{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "\n",
    "## Wyatt Smith\n",
    "\n",
    "## Physics 494\n",
    "\n",
    "### 1) Generalizing a Convolutional Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./include/header.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from tqdm import trange,tqdm\n",
    "sys.path.append('./include')\n",
    "import ml4s\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# determine the properties\n",
    "rows,cols = x_train[0].shape\n",
    "num_classes = 10\n",
    "\n",
    "# reshape and rescale\n",
    "x_train = x_train.reshape(x_train.shape[0], rows*cols).astype('float32')/255\n",
    "x_test = x_test.reshape(x_test.shape[0], rows*cols).astype('float32')/255\n",
    "\n",
    "# use a built-in function to get 1-hot encoding\n",
    "y_train_hot = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_hot = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit_array(x,y, show_prediction=False):\n",
    "    '''Expects a list of digits (x) and associated labels (y)'''\n",
    "    \n",
    "    # determine the number of rows and columns of our image array\n",
    "    num_digits = x.shape[0]\n",
    "    num_cols = int(np.sqrt(num_digits))\n",
    "    num_rows = num_digits//num_cols + 1\n",
    "\n",
    "    fig,ax = plt.subplots(nrows=num_rows,ncols=num_cols,sharex=True,sharey=True,\n",
    "                          figsize=(num_cols,num_rows))\n",
    "    \n",
    "    # plot all the numbers\n",
    "    for i,cax in enumerate(ax.flatten()):\n",
    "        if i < num_digits:\n",
    "            cax.matshow(x[i].reshape(28,28), cmap='binary')\n",
    "            cax.axis('off')\n",
    "            if show_prediction:\n",
    "                cax.text(0.99,0.99,f'{y[i]}',horizontalalignment='right',verticalalignment='top', \n",
    "                         transform=cax.transAxes, fontsize=8, color='r')\n",
    "        else:\n",
    "            cax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "[\n",
    "    layers.Dense(128,input_shape=(rows*cols,),activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4347 - accuracy: 0.8767 - val_loss: 0.1341 - val_accuracy: 0.9607\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1254 - accuracy: 0.9637 - val_loss: 0.1086 - val_accuracy: 0.9676\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0803 - accuracy: 0.9765 - val_loss: 0.0887 - val_accuracy: 0.9734\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0566 - accuracy: 0.9820 - val_loss: 0.0867 - val_accuracy: 0.9737\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0440 - accuracy: 0.9863 - val_loss: 0.0803 - val_accuracy: 0.9763\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0330 - accuracy: 0.9893 - val_loss: 0.0770 - val_accuracy: 0.9771\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0253 - accuracy: 0.9922 - val_loss: 0.0861 - val_accuracy: 0.9755\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0832 - val_accuracy: 0.9757\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.0827 - val_accuracy: 0.9775\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0857 - val_accuracy: 0.9764\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "training = model.fit(x_train,y_train_hot, batch_size=batch_size, epochs=epochs,\n",
    "                     verbose=1, validation_data=(x_test,y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 260,
       "width": 263
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imread(\"./data1/zero.png\")\n",
    "image = plt.imread(\"./data1/zero.png\")\n",
    "norm_image = pnorm(image)\n",
    "plt.imshow(image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "\n",
    "def norm(file):\n",
    "    img = Image.open(file)\n",
    "    smol = img.resize((28, 28))\n",
    "    smol = ImageOps.grayscale(smol)\n",
    "    scale = np.array(smol, dtype='float32') ## The Type Matters Here!!\n",
    "    scale -= scale.min()\n",
    "    scale /= scale.max()\n",
    "    \n",
    "    final = np.ones((28,28))\n",
    "    final -= scale\n",
    "    \n",
    "    for i in range(28):\n",
    "        for j in range(28):       \n",
    "            if final[i][j] < 0.08:\n",
    "                final[i][j] = 0.0\n",
    "            else:\n",
    "                pass\n",
    "    final /= final.max()\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[9.4226021e-01, 3.3159886e-05, 5.6598336e-02, 1.9285508e-04, 6.7203032e-06, 3.2425953e-05, 6.2060835e-08,\n",
       "        3.9703934e-08, 1.1163457e-08, 8.7626465e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(image2.reshape(1,rows*cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = norm(\"./data1/zero.png\")\n",
    "img1 = norm(\"./data1/one.png\")\n",
    "img2 = norm(\"./data1/two.png\")\n",
    "img3 = norm(\"./data1/three.png\")\n",
    "img4 = norm(\"./data1/four.png\")\n",
    "img5 = norm(\"./data1/five.png\")\n",
    "img6 = norm(\"./data1/six.png\")\n",
    "img7 = norm(\"./data1/seven.png\")\n",
    "img8 = norm(\"./data1/eight.png\")\n",
    "img9 = norm(\"./data1/nine.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[2.0003474e-05, 9.6192664e-01, 1.2337525e-02, 3.8419769e-03, 2.3830305e-06, 5.7207416e-03, 1.0608023e-02,\n",
       "        1.8205608e-05, 5.5242139e-03, 4.0239192e-07]], dtype=float32)>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img1.reshape(1,rows*cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[8.4775183e-06, 1.4451701e-04, 9.9627823e-01, 2.7800517e-04, 2.3760409e-04, 5.2862146e-05, 1.8361749e-05,\n",
       "        8.5423875e-04, 2.1150084e-03, 1.2658236e-05]], dtype=float32)>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img2.reshape(1,rows*cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[1.3173549e-04, 7.4923687e-02, 2.1778502e-02, 3.5890087e-01, 4.8232347e-02, 9.6752450e-02, 6.0626331e-05,\n",
       "        1.8683061e-02, 1.4112191e-03, 3.7912554e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img3.reshape(1,rows*cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[1.3613504e-12, 1.8145638e-06, 1.6576311e-07, 2.9257719e-05, 9.9932897e-01, 1.4642105e-04, 1.9214036e-10,\n",
       "        3.4599652e-06, 1.9323328e-07, 4.8974773e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img4.reshape(1,rows*cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[5.6705920e-12, 2.5291962e-08, 9.7277889e-06, 2.2698255e-02, 1.9717118e-06, 9.7561502e-01, 2.4662489e-07,\n",
       "        1.8675082e-07, 4.1394171e-05, 1.6332377e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img5.reshape(1,rows*cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[3.6813048e-04, 1.1136690e-08, 1.2661633e-03, 1.4191218e-06, 1.9013009e-03, 8.9082739e-04, 9.9550676e-01,\n",
       "        1.4964697e-05, 3.5625228e-05, 1.4798777e-05]], dtype=float32)>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img6.reshape(1,rows*cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[2.2833872e-05, 4.6973219e-03, 4.5534261e-02, 4.4722017e-02, 5.4885266e-05, 6.8120607e-05, 1.9193633e-06,\n",
       "        6.8943983e-01, 1.5580635e-02, 1.9987828e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img7.reshape(1,rows*cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[3.8971286e-04, 5.5609522e-05, 8.5779041e-01, 1.5264069e-02, 2.6348818e-03, 1.4395030e-04, 1.5133622e-05,\n",
       "        1.7220716e-05, 1.2314250e-01, 5.4652872e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img8.reshape(1,rows*cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[3.7537649e-09, 8.5980690e-07, 1.2543705e-05, 2.6381348e-04, 9.9948561e-01, 8.1638154e-06, 6.4060307e-10,\n",
       "        9.7181355e-06, 2.1464213e-04, 4.6559694e-06]], dtype=float32)>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img9.reshape(1,rows*cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it did not like all of my numbers...  \n",
    "\n",
    "I did not have enough time to fix this unfortunately. I spend most of my time on part (a) and, unwisely, working on the final project (before I had this done). For part (a), my original normalizing/rescaling procedure from last time did not work-- it gave me a blank image, I do not know why... talking to some cohorts, they reccommended PIL, so I used that and finally got it working. \n",
    "\n",
    "I got all my data for the final project preprocessed, however. I tend to get obsessive over certain things like thisl ultimately it came to the detriment of this assignment. I did not have time to get a new dataset properly made from my images to retrain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Final Project\n",
    "\n",
    "We already gave the slide, but here is part of the \"script\" I had prepared in case we missed anything (I think we did): \n",
    "\n",
    ">Slide I What is a Elliptic Curve? \n",
    ">\n",
    ">An Elliptic Curve is a plane curve over some field,  K, satisfying the Weierstrass equation with nonzero determinant (the relevant formula are displayed here). \n",
    "The set of rational points on an elliptic curve along with an additional point at infinity form a group, usually denoted E(Q).\n",
    "The binary operation we use to add points has a nice geometric description-- any two points add to the unique third point collinear to them. \n",
    "Group Structure\n",
    "One of the first things we look at in a group is its structure. \n",
    "It turns out that E(Q) is finitely generated and abelian, so we can decompose it into a free part and and a torsion subgroup, consisting of the elements of infinite and finite order respectively. \n",
    "Relevant features: \n",
    "Some relevant features of an elliptic curve are its rank, the order of its torsion subgroup, and the number of integer points it contains. \n",
    "*Point to these in the equation*\n",
    "The goal of our project is to use Machine learning to predict some of these properties based on a curve’s Weierstrass Coefficients. \n",
    "We plan on predicting the number of integer points minimally, and potentially predicting the torsion order if we have time.\n",
    "Here is a picture of an elliptic curve \n",
    ">\n",
    ">Slide II Procedure: \n",
    ">\n",
    ">We will obtain all our data from the The L-functions and Modular Forms Database, which contains tons of data about different objects arising in number theory, including a huge list of elliptic curves where we know all of the aforementioned invariants. \n",
    "So, from here we will pull our relevant curves and their appropriate label. While the database is expansive, it appears that  there are only enough data points to reliably sample curves with zero or one integral points.\n",
    "For this reason, our model will be a binary classifier, which will take the coefficients as an input, and output a zero or a one. \n",
    "There is one step of preprocessing we will do-- other research looking at this problem have discovered that you can get better accuracies if you instead pass a curve’s Euler Coefficients into the network instead of its Weierstrass Coefficients. \n",
    "This is probably because the Weierstrass Coefficients can take on a large range of values, whereas the Euler Coefficients are generally small integers. \n",
    "We can easily calculate the first hundred or so Euler coefficients quickly  in SageMath, which is like Python but with built-in Number Theory. \n",
    "The exact number of Euler Coefficients we compute will determine the architecture of our network; the existing literature suggests that we should get high accuracy with the first 500 coefficients. \n",
    "One of the papers we cite claims to get accuracies in the high 90s for this problem. They do not disclose their particular architecture, however, so this is something we will play around with. \n",
    ">\n",
    ">References: \n",
    ">\n",
    ">J. H. Silverman and  J. T. Tate, Rational Points on Elliptic Curves, second edition, Undergraduate Texts in  \t\t\tMathematics, 2015. \n",
    ">\n",
    ">K. Ireland and M. Rosen, A Classical Introduction to Modern Number Theory, second edition, Graduate Texts in Mathematics 84, Springer, 1998. \n",
    ">\n",
    ">The LMFDB Collaboration, The L-functions and Modular Forms Database, https://www.lmfdb.org, 2020 \t\t\t [Online, accessed April 7, 2021]. \n",
    ">\n",
    ">Y.-H. He, K.-H. Lee, and T. Oliver, Machine-Learning Arithmetic Curves, arXiv:2012.04084. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ml4s)",
   "language": "python",
   "name": "ml4s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
